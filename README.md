# Air Quality Analysis
![Air Quality Dashboard Banner](figures/image.jpg)
## Dataset Description

This project analyzes integrated air quality and meteorological data across 6 major US cities (Los Angeles, Chicago, Cleveland, Detroit, Houston, Sacramento) over a 60-day winter period (December 2023 - January 2024). The dataset contains 360 total records (6 cities × 60 days) with 15 features including pollution metrics (PM2.5, PM10, AQI, ozone, NO₂, SO₂, CO, CO₂) and weather variables (temperature, humidity, precipitation, wind speed, pressure).

The dataset is well-suited for this analysis with a compact size of approximately 2MB (far below the 100GB repository limit), providing sufficient temporal depth for pattern identification while remaining computationally efficient. The winter timeframe captures cold weather pollution patterns, and the geographic diversity across different US regions enables comparative analysis of urban air quality under varying climatic and industrial conditions. Key features include daily measurements with no missing values, standardized units across all cities, and integration of both pollution and meteorological parameters for comprehensive environmental analysis.

## Business Requirements

This project analyzes air quality across six US cities to support regulatory compliance, public health protection, and urban planning. It enables stakeholders to monitor pollution levels, identify exceedances of WHO and EPA standards, and develop targeted interventions to reduce health risks and avoid regulatory penalties.

Key requirements include integrating air quality and weather data to identify pollution patterns, providing comparative analysis between cities to highlight best practices, and generating actionable insights for evidence-based decision-making. The system must deliver real-time monitoring, automated reporting, and scalable analysis capabilities.

Success will be measured by improved pollution forecasting, identification of high-risk periods for vulnerable populations, and data-driven policy recommendations that lead to measurable air quality improvements across the studied urban centers.

## Hypotheses and How to Validate

1. **Air pollutant concentrations follow a given distribution**  
   The first hypothesis focuses on understanding patterns, variability, and trends in weather and air quality data. Descriptive statistics, including the mean, median, standard deviation, and quartiles, are used to summarise central tendency and dispersion.

2. **Weather's effect can be used in Clustering Weather/Air Regimes**  
   K-Means clustering is employed to group observations based on similarity in meteorological conditions and air quality indicators. Because K-Means requires the number of clusters to be specified in advance, cluster validation techniques are applied. The elbow method is used to examine within-cluster variance across different values of k, while the silhouette score is used to assess cluster cohesion and separation.

3. **Weather-driven patterns can be used to predict Engineered AQI Risk Levels**  
   Supervised multiclass machine learning was applied to test this hypothesis.

## Project Plan

To help plan we used a GitHub project planning board which can be found [here]. The project board gave a structured approach to planning that allowed us to identify the steps and the priority that we should give them.

To ideate hypotheses we used a mixture of EDA, literature review and prompts from Co-pilot.

Data was collected using APIs from Open-Meteo website, processed in Jupyter notebook, analyzed using statistical tests in Python and interpreted using a mix of literature review and generative AI.

## The Rationale to Map the Business Requirements to the Data Visualisations

1. **Interactive Plotly Distribution Plots**  
   The first plot is an interactive Plotly distribution plot of all numeric variables of air quality. The intention was to have a view of the distribution patterns, skewness, etc.

2. **Mean Annual PM2.5 Concentrations by City**  
   This plot compares mean annual PM2.5 concentrations by city against WHO and US EPA air quality standards. This was to provide a comparison of the main pollutant across the cities.

3. **Mean AQI Across Cities**  
   This visualization shows mean AQI across the cities. AQI is an index that is calculated and used as an indicator.

4. **Time Series Plots**  
   The next two visualizations are time series plots demonstrating levels of both AQI and PM2.5 by time across cities.

## Analysis Techniques Used

- **Data cleaning in pandas using a Jupyter Notebook** gave a structured workflow that allows one to follow steps.
- **EDA visualizations in Python** allow data exploration with a wide range of visualization libraries.
- **Generative AI** specifically Co-pilot was used for hypothesis ideation, code debugging, code generation and storytelling.
- **Scikit-Learn** was used for machine learning as it's a relatively easy-to-use library for machine learning tasks.
- **Git** was used for version control.

## Ethical Considerations

**Data Attribution:** All meteorological and air quality data must be properly attributed to Open-Meteo under their CC BY 4.0 license, with clear disclosure of model limitations and uncertainties.

**Public Responsibility:** Health advisories based on predictions must avoid alarmist language, include uncertainty estimates, and never replace official emergency warnings or medical advice.

**Algorithmic Fairness:** Geographic biases in data resolution must be acknowledged, ensuring transparency about varying accuracy across regions and avoiding stigmatization of specific communities.

## Dashboard Design

**Main Page: Air Quality Dashboard**  
Has side panel with 5 tabs for all other pages. Main content includes tabs of the other pages.

**Overview Page**  
Main content includes dataset preview, basic statistics, and fundamental visualizations. Side panel has tabs for all pages.

**Insights Page**  
Has city comparisons, detailed analysis, and AQI health guidelines. Side panel has all pages tabs, filter settings for selecting city comparison by the metric.

**Monitoring Page**  
Has real-time trends, correlations, and city-level monitoring.

**Predictions Page**  
Has atmospheric regime analysis and AQI risk forecasting.

## Unfixed Bugs

1. **Multiclass prediction model was underfitting**, even though I used GridCV and hyperparameter tuning to get ExtraTrees classifier and n_components to 20. Needs more time for refining.

2. **Streamlit deployment challenge** with tracking files while online. First page shows loaded dataframe but prediction page gives error of having wrong dataframe with just 2 features.

## Development Roadmap

1. The LMS material on K-Means clustering had a few errors and it heavily jeopardized my progress. At one point it referred to `df_elbows` instead of `df_analysis`.

2. Instead of training and fitting the data during clustering, the method just trains and gives a label which is subsequently used for supervised training as a label for metrics. Separate prediction on this cluster should have been used to get cluster IDs instead of label to enable smooth pipeline.

## Deployment

The app can be found at: https://arphaxad1985-air-quality-analysis-dashboardair-quality-6oh1ha.streamlit.app/

## Main Data Analysis Libraries

- pandas
- numpy
- matplotlib
- seaborn
- scikit-learn
- jupyter

## AI Tools

- Co-Pilot
- Google Search with AI responses

## Credits

- **Code Institute**: https://learn.codeinstitute.net/ and GitHub: https://github.com/Code-Institute-Solutions/da-README-template, https://github.com/Code-Institute-Org/data-analytics-template
- **CoPilot** for code correction, generation utilizing various prompts

## Content and Media

- **Dataset**: https://open-meteo.com
- **Instructions and project templates**: Code Institute https://learn.codeinstitute.net/

## Media

- The photos used on the home and sign-up page are from open-source sites
- The images used for PowerPoint presentation were taken from Leonardo.ai, an open-source site

## Acknowledgement

My appreciation to everyone who supported me during this process.